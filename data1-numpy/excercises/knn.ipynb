{"cells":[{"attachments":{},"cell_type":"markdown","id":"4ab75e99","metadata":{"id":"4ab75e99","tags":["pdf-title"]},"source":["# k-Nearest Neighbor (kNN) exercise\n","\n","Below is a simple explanation of the KNN model. You don't have to understand this yet.\n","\n","The kNN classifier consists of two stages:\n","\n","- During training, the classifier takes the training data and simply remembers it\n","- During testing, kNN classifies every test image by comparing to all training images and transfering the labels of the k most similar training examples\n","- The value of k is cross-validated"]},{"cell_type":"code","execution_count":null,"id":"0ff438a8","metadata":{"executionInfo":{"elapsed":1233,"status":"ok","timestamp":1686884196001,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"0ff438a8","tags":["pdf-ignore"]},"outputs":[],"source":["# Run some setup code for this notebook.\n","\n","import random\n","import numpy as np\n","from data_utils import load_CIFAR10\n","import matplotlib.pyplot as plt\n","\n","# This is a bit of magic to make matplotlib figures appear inline in the notebook\n","# rather than in a new window.\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# Some more magic so that the notebook will reload external python modules;\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"id":"75a3fe89","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5665,"status":"ok","timestamp":1686884201663,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"75a3fe89","outputId":"afa47c1c-69d9-458d-ae04-87fd544b074b","tags":["pdf-ignore"]},"outputs":[],"source":["# Load the raw CIFAR-10 data.\n","cifar10_dir = 'dataset/cifar-10-batches-py'\n","\n","# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n","try:\n","   del X_train, y_train\n","   del X_test, y_test\n","   print('Clear previously loaded data.')\n","except:\n","   pass\n","\n","X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n","\n","# As a sanity check, we print out the size of the training and test data.\n","print('Training data shape: ', X_train.shape)\n","print('Training labels shape: ', y_train.shape)\n","print('Test data shape: ', X_test.shape)\n","print('Test labels shape: ', y_test.shape)"]},{"cell_type":"code","execution_count":null,"id":"0ce646dd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":665},"executionInfo":{"elapsed":2498,"status":"ok","timestamp":1686884204151,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"0ce646dd","outputId":"d06d26e6-4120-4fc7-92fb-4005db72782f","tags":["pdf-ignore"]},"outputs":[],"source":["# Visualize some examples from the dataset.\n","# We show a few examples of training images from each class.\n","classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","num_classes = len(classes)\n","samples_per_class = 7\n","for y, cls in enumerate(classes):\n","    idxs = np.flatnonzero(y_train == y)\n","    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n","    for i, idx in enumerate(idxs):\n","        plt_idx = i * num_classes + y + 1\n","        plt.subplot(samples_per_class, num_classes, plt_idx)\n","        plt.imshow(X_train[idx].astype('uint8'))\n","        plt.axis('off')\n","        if i == 0:\n","            plt.title(cls)\n","plt.show()"]},{"cell_type":"code","execution_count":9,"id":"44a4a005","metadata":{},"outputs":[],"source":["# Subsample the data for more efficient code execution in this exercise\n","num_training = 2000"]},{"cell_type":"code","execution_count":null,"id":"a8aff94c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1686884204152,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"a8aff94c","outputId":"c6f4988e-595b-4523-b1a2-a03bc52aca90","tags":["pdf-ignore"]},"outputs":[],"source":["mask = list(range(num_training))\n","X_train = X_train[mask]\n","y_train = y_train[mask]\n","\n","num_test = 500\n","mask = list(range(num_test))\n","X_test = X_test[mask]\n","y_test = y_test[mask]\n","\n","# Reshape the image data into rows\n","X_train = np.reshape(X_train, (X_train.shape[0], -1))\n","X_test = np.reshape(X_test, (X_test.shape[0], -1))\n","print(X_train.shape, X_test.shape)"]},{"cell_type":"code","execution_count":null,"id":"a822743b","metadata":{"executionInfo":{"elapsed":846,"status":"ok","timestamp":1686884204992,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"a822743b","tags":["pdf-ignore"]},"outputs":[],"source":["from k_nearest_neighbor import KNearestNeighbor\n","\n","# Create a kNN classifier instance.\n","# Remember that training a kNN classifier is a noop:\n","# the Classifier simply remembers the data and does no further processing\n","classifier = KNearestNeighbor()\n","classifier.train(X_train, y_train)"]},{"attachments":{},"cell_type":"markdown","id":"b45f4eb5","metadata":{"id":"b45f4eb5"},"source":["We would now like to classify the test data with the kNN classifier. Recall that we can break down this process into two steps:\n","\n","1. First we must compute the distances between all test examples and all train examples.\n","2. Given these distances, for each test example we find the k nearest examples and have them vote for the label\n","\n","Lets begin with computing the distance matrix between all training and test examples. For example, if there are **Ntr** training examples and **Nte** test examples, this stage should result in a **Nte x Ntr** matrix where each element (i,j) is the distance between the i-th test and j-th train example.\n","\n","**Note: For the three distance computations that we require you to implement in this notebook, DO NOT use the np.linalg.norm() function that numpy provides. However, you may use it to check that your implementation is correct, but I won't show you how.**\n","\n","First, open `k_nearest_neighbor.py` and implement the function `compute_distances_two_loops` that uses a (very inefficient) double loop over all pairs of (test, train) examples and computes the distance matrix one element at a time."]},{"attachments":{},"cell_type":"markdown","id":"93d5ed9a","metadata":{},"source":["__NOTE:__ The comments on accuracy are applicable for `num_training` = 5000"]},{"cell_type":"code","execution_count":null,"id":"71778c89","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26746,"status":"ok","timestamp":1686884231735,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"71778c89","outputId":"3b75fa7c-6261-471f-fe26-b98d90b050cc"},"outputs":[],"source":["# Open cs231n/classifiers/k_nearest_neighbor.py and implement\n","# compute_distances_two_loops.\n","\n","# Test your implementation:\n","dists = classifier.compute_distances_two_loops(X_test)\n","print(dists.shape)"]},{"cell_type":"code","execution_count":null,"id":"3ddf01d0","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1686884231735,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"3ddf01d0","outputId":"9daba072-4965-46a8-dee0-0306aabd6cf8"},"outputs":[],"source":["# We can visualize the distance matrix: each row is a single test example and\n","# its distances to training examples\n","plt.imshow(dists, interpolation='none')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"3ec52360","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1686884231735,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"3ec52360","outputId":"9424a70d-0b81-46e5-8854-f0d997a3d984"},"outputs":[],"source":["# Now implement the function predict_labels and run the code below:\n","# We use k = 1 (which is Nearest Neighbor).\n","y_test_pred = classifier.predict_labels(dists, k=1)\n","\n","# Compute and print the fraction of correctly predicted examples\n","num_correct = np.sum(y_test_pred == y_test)\n","accuracy = float(num_correct) / num_test\n","print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"]},{"attachments":{},"cell_type":"markdown","id":"0710e525","metadata":{"id":"0710e525"},"source":["You should expect to see approximately `27%` accuracy. Now lets try out a larger `k`, say `k = 5`:"]},{"cell_type":"code","execution_count":null,"id":"852c51b8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1686884231735,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"852c51b8","outputId":"a071a7fc-aacf-4695-836e-4b4fa7481a36"},"outputs":[],"source":["y_test_pred = classifier.predict_labels(dists, k=5)\n","num_correct = np.sum(y_test_pred == y_test)\n","accuracy = float(num_correct) / num_test\n","print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"]},{"attachments":{},"cell_type":"markdown","id":"973c4790","metadata":{"id":"973c4790"},"source":["You should expect to see a slightly better performance than with `k = 1`."]},{"cell_type":"code","execution_count":null,"id":"3426b64c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26168,"status":"ok","timestamp":1686884257893,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"3426b64c","outputId":"9c96246d-362e-4b31-b88e-36c364d57f32","tags":["pdf-ignore-input"]},"outputs":[],"source":["# Now lets speed up distance matrix computation by using partial vectorization\n","# with one loop. Implement the function compute_distances_one_loop and run the\n","# code below:\n","dists_one = classifier.compute_distances_one_loop(X_test)\n","\n","# To ensure that our vectorized implementation is correct, we make sure that it\n","# agrees with the naive implementation. There are many ways to decide whether\n","# two matrices are similar; one of the simplest is the Frobenius norm. In case\n","# you haven't seen it before, the Frobenius norm of two matrices is the square\n","# root of the squared sum of differences of all elements; in other words, reshape\n","# the matrices into vectors and compute the Euclidean distance between them.\n","difference = np.linalg.norm(dists - dists_one, ord='fro')\n","print('One loop difference was: %f' % (difference, ))\n","if difference < 0.001:\n","    print('Good! The distance matrices are the same')\n","else:\n","    print('Uh-oh! The distance matrices are different')"]},{"cell_type":"code","execution_count":null,"id":"18368c3a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509,"status":"ok","timestamp":1686884258382,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"18368c3a","outputId":"fc7f7847-dadc-43be-c98b-a72899da74c5","scrolled":true,"tags":["pdf-ignore-input"]},"outputs":[],"source":["# Now implement the fully vectorized version inside compute_distances_no_loops\n","# and run the code\n","dists_two = classifier.compute_distances_no_loops(X_test)\n","\n","# check that the distance matrix agrees with the one we computed before:\n","difference = np.linalg.norm(dists - dists_two, ord='fro')\n","print('No loop difference was: %f' % (difference, ))\n","if difference < 0.001:\n","    print('Good! The distance matrices are the same')\n","else:\n","    print('Uh-oh! The distance matrices are different')"]},{"cell_type":"code","execution_count":null,"id":"c9f2332f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53059,"status":"ok","timestamp":1686884311438,"user":{"displayName":"Duy Long Nguyễn","userId":"15729805888761804706"},"user_tz":-420},"id":"c9f2332f","outputId":"41f40f91-1a96-4f8b-b130-e46f33fefa3b","tags":["pdf-ignore-input"],"test":"no_loop"},"outputs":[],"source":["# Let's compare how fast the implementations are\n","def time_function(f, *args):\n","    \"\"\"\n","    Call a function f with args and return the time (in seconds) that it took to execute.\n","    \"\"\"\n","    import time\n","    tic = time.time()\n","    f(*args)\n","    toc = time.time()\n","    return toc - tic\n","\n","two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)\n","print('Two loop version took %f seconds' % two_loop_time)\n","\n","one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)\n","print('One loop version took %f seconds' % one_loop_time)\n","\n","no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)\n","print('No loop version took %f seconds' % no_loop_time)\n"]},{"attachments":{},"cell_type":"markdown","id":"7465beb3","metadata":{},"source":["You should see significantly faster performance with the fully vectorized implementation!"]},{"attachments":{},"cell_type":"markdown","id":"c43cc358","metadata":{},"source":["## Note:\n","\n","Depending on the machine you're using, you might not see a speedup when you go from two loops to one loop, and might even see a slow-down. "]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":5}
